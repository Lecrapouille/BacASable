# Commande Optimale

## Introduction √† la m√©thode de Lagrange

La m√©thode des multiplicateurs de Lagrange sert √† r√©soudre un probl√®me d'optimisation avec des contraintes.

On veut **minimiser** (ou maximiser) une fonction $f(x, u)$ sous **contraintes** $g(x, u) = 0$.

Exemple :

> Trouver le point $(x, y)$ qui minimise $f(x, y) = x^2 + y^2$
> sous la contrainte : $g(x, y) = x + y - 1 = 0$

### Qu'est-ce qu'une contrainte ?

Imaginons qu'on veuille minimiser le co√ªt de carburant sur un trajet. Mais aussi **arriver √† l'heure**. Cette condition est une **contrainte** : on ne peut pas faire ce que l'on veut librement.

### Id√©e principale

Ne pouvant pas minimiser $f$ librement, on doit rester sur la ligne $x + y = 1$. L‚Äôid√©e est d‚Äôint√©grer la contrainte dans le probl√®me, en la combinant avec une fonction auxiliaire $\lambda$.

On √©crit un **Lagrangien** :

$$\mathcal{L}(x, y, \lambda) = f(x, y) + \lambda \cdot g(x, y)$$

Ici :

$$\mathcal{L}(x, y, \lambda) = x^2 + y^2 + \lambda (x + y - 1)$$

Ensuite on cherche les points o√π tous les **d√©riv√©s (gradients)** sont nuls :

$$\nabla \mathcal{L} = 0 \quad \text{(syst√®me d'√©quations)}$$

On d√©rive par rapport √† $x$, $y$, et $\lambda$, et on r√©sout le syst√®me d'√©quations :

$$\frac{\partial \mathcal{L}}{\partial x} = 0, \quad \frac{\partial \mathcal{L}}{\partial y} = 0, \quad \frac{\partial \mathcal{L}}{\partial \lambda} = 0$$

C‚Äôest √ßa, la **m√©thode de Lagrange** : on transforme un probl√®me √† contraintes en un probl√®me sans contrainte avec un multiplicateur $\lambda$.

* * *

## Commande optimale : la m√™me id√©e, mais en dynamique

En **commande optimale**, on cherche une **commande $u(t)$** qui **minimise un co√ªt** tout en respectant une **√©quation diff√©rentielle** (l‚Äô√©volution de l‚Äô√©tat) $\dot{x}(t) = f(x(t), u(t))$.

Exemple:

> On veut donc trouver une fonction $u(t)$ qui rend la somme des carr√©s de $u$ et de $x$ aussi petite que possible, tout en respectant la contrainte $\dot{x}(t) = u(t)$ avec une condition initiale $x(0)$ connue.

On veut minimiser $J$:

$$J = \int_0^T (x^2(t) + u^2(t)) \, dt$$

Ici :
- $x(t)$ est l‚Äô**√©tat**
- $u(t)$ est le **contr√¥le** (la commande)
- La contrainte est **dynamique** : respecter l'√©quation $x' = u$

Note: On ajoute g√©n√©ralement une p√©nalit√© $\phi$ sur l'√©tat final $x_T$:

$$J = \int_0^T (x^2(t) + u^2(t)) \, dt + \phi(x_T)$$

* * *

### M√©thode de Pontryagin (ou Lagrange continue)

On fait comme avant : on construit un **Lagrangien**, mais en version continue. On introduit une fonction $\lambda(t)$ appel√©e **multiplicateur de Lagrange**, ou **co√ªt adjoint** :

$$\mathcal{L}(x, u, \lambda) = x^2 + u^2 + \lambda ( \dot{x} - u )$$

On va construire un objet plus utile : le **Hamiltonien**.

$$H(x, u, \lambda) = x^2 + u^2 + \lambda \cdot f(x, u)$$

Ici, $f(x, u) = u$, donc :

$$H(x, u, \lambda) = x^2 + u^2 + \lambda u$$

Ensuite, on applique les √©quations suivantes :

1.  **√âquation d‚Äô√©tat :**

    $$\dot{x} = \frac{\partial H}{\partial \lambda} = u$$

2.  **√âquation du co√ªt adjoint** (on remonte dans le temps) :

    $$\dot{\lambda} = -\frac{\partial H}{\partial x} = -2x$$

3.  **Condition d‚Äôoptimalit√©** (optimisation) :

    $$\frac{\partial H}{\partial u} = 2u + \lambda = 0 \Rightarrow u = -\frac{\lambda}{2}$$

#### Remarque: Pourquoi on remonte le temps ?

Parce que la condition sur $\lambda$ est donn√©e **√† la fin** (ex : $\lambda(T) = 0$) !   On conna√Æt $x(0) = 1$, mais pas $\lambda(0)$. C‚Äôest ce qu‚Äôon appelle un **probl√®me √† deux points** :

*   $x$ part de $t=0$

*   $\lambda$ part de $t=T$

On doit "tirer" dans le bon sens pour que √ßa colle √† la fin.

#### Remarque: $\lambda$ **produit scalaire** ou **multiplication** ?

La notation:

$$\lambda(t) \cdot f(x(t), u(t))$$

- En dimension 1: est une **multiplication classique de scalaires**. Par exemple: $\lambda(t) \cdot (\dot{x}(t) - u(t))$ ce qu‚Äôon fait ici, c‚Äôest ajouter au co√ªt une "p√©nalit√©" si $\dot{x} \ne u$, via ce produit.

- En dimension plus grande (ex : plusieurs √©tats et contr√¥les): Si on avait un vecteur $x \in \mathbb{R}^n$, alors $\lambda$ serait aussi un vecteur et :

$$\lambda(t) \cdot f(x(t), u(t)) = \text{produit scalaire} = \sum_{i=1}^n \lambda_i(t) f_i(x(t), u(t))$$

* * *

### R√©solution compl√®te

On a donc ce syst√®me :

$$\dot{x} = u = -\frac{\lambda}{2}$$

$$\dot{\lambda} = -2x$$

Et on sait que $x(0) = 1$, on peut aussi imposer $\lambda(T) = 0$ comme condition terminale (typique en commande optimale).

On peut r√©soudre ce syst√®me num√©riquement (m√©thode de Runge-Kutta, Euler, etc.).

```cpp
#include <iostream>
#include <vector>
#include <cmath>

// R√©solution avec Euler, pas super pr√©cis, mais √ßa illustre l'id√©e.
int main()
{
    const double T = 5.0;
    const int N = 1000;
    const double dt = T / N;

    std::vector<double> x(N + 1, 0.0);
    std::vector<double> lambda(N + 1, 0.0);
    std::vector<double> u(N + 1, 0.0);

    // Condition initiale x(0) = 1
    x[0] = 1.0;

    // Condition finale lambda(T) = 0
    lambda[N] = 0.0;

    // Backward Euler for lambda (remonter le temps)
    for (int i = N - 1; i >= 0; --i)
    {
        lambda[i] = lambda[i + 1] + dt * 2 * x[i + 1];  // \dot{\lambda} = -2x
    }

    // Forward Euler for x (avancer dans le temps)
    for (int i = 0; i < N; ++i)
    {
        u[i] = -lambda[i] / 2;              // optimalit√© : u = -lambda/2
        x[i + 1] = x[i] + dt * u[i];        // \dot{x} = u
    }

    // Affichage de quelques valeurs
    for (int i = 0; i <= N; i += N / 10)
    {
        std::cout << "t=" << i * dt
                  << ", x=" << x[i]
                  << ", u=" << u[i]
                  << ", lambda=" << lambda[i]
                  << std::endl;
    }

    return 0;
}
```

### üß† Commentaires :

*   `lambda[i] = lambda[i+1] + dt * 2 * x[i+1]` : c‚Äôest l‚Äô√©quation $\dot{\lambda} = -2x$

*   `u = -lambda/2` : c‚Äôest la condition d‚Äôoptimalit√©

*   `x[i+1] = x[i] + dt * u[i]` : c‚Äôest l‚Äô√©volution de l‚Äô√©tat


* * *


üß© 8. R√©sum√©
------------

| Concept | R√¥le |
| --- | --- |
| Contrainte | Ce qu'on doit respecter (ici : $x'=u$) |
| M√©thode de Lagrange | Ajoute un multiplicateur pour g√©rer les contraintes |
| Hamiltonien | Fonction pour combiner √©tat, contr√¥le et adjoint |
| Gradient / d√©riv√©es | Trouver les minima (ou maxima) en r√©solvant des √©quations |
| Conditions initiales | Ce qu‚Äôon conna√Æt au d√©but (ex : x(0) = 1) |
| Conditions finales | Ce qu‚Äôon conna√Æt √† la fin (ex : $\lambda(T) = 0$) |
| Remonter le temps | N√©cessaire car la contrainte sur $\lambda$ est fix√©e √† la fin |